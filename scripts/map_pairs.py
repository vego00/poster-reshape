import os
import json
import torch
import numpy as np
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
from scipy.optimize import linear_sum_assignment
from tqdm import tqdm
import shutil
import matplotlib.pyplot as plt
import argparse

# ì„¤ì •
VERTICAL_DIR = "data/vertical"
HORIZONTAL_DIR = "data/horizontal"
OUTPUT_DIR = "data/pairs"
VISUALIZATION_DIR = "data/visualization"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

def visualize_pairs(pairs, movie_name, show=False):
    """ë§¤ì¹­ëœ ì´ë¯¸ì§€ ìŒì„ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    n_pairs = len(pairs)
    if n_pairs == 0:
        return

    # ì‹œê°í™” ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    vis_dir = os.path.join(VISUALIZATION_DIR, movie_name)
    os.makedirs(vis_dir, exist_ok=True)

    # ê° ìŒë§ˆë‹¤ ì‹œê°í™”
    for i, pair in enumerate(pairs):
        # ì´ë¯¸ì§€ ë¡œë“œ
        vertical_img = Image.open(pair["vertical"])
        horizontal_img = Image.open(pair["horizontal"])

        # ì‹œê°í™”
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
        ax1.imshow(vertical_img)
        ax1.set_title(f"Vertical\nScore: {pair['score']:.4f}")
        ax1.axis('off')
        
        ax2.imshow(horizontal_img)
        ax2.set_title("Horizontal")
        ax2.axis('off')

        plt.suptitle(f"Pair {i+1}/{n_pairs} - {movie_name}")
        plt.tight_layout()

        # ê²°ê³¼ ì €ì¥
        output_path = os.path.join(vis_dir, f"pair_{i+1}.png")
        plt.savefig(output_path)
        
        if show:
            plt.show()
        else:
            plt.close()

def copy_paired_images(pairs, movie_name):
    """ë§¤ì¹­ëœ ì´ë¯¸ì§€ ìŒì„ ìƒˆë¡œìš´ í´ë”ì— ë³µì‚¬í•©ë‹ˆë‹¤."""
    if not pairs:
        return

    # ì˜í™”ë³„ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    movie_pairs_dir = os.path.join(OUTPUT_DIR, movie_name)
    os.makedirs(movie_pairs_dir, exist_ok=True)

    # ê° ìŒë§ˆë‹¤ í´ë” ìƒì„± ë° ì´ë¯¸ì§€ ë³µì‚¬
    for i, pair in enumerate(pairs):
        pair_dir = os.path.join(movie_pairs_dir, f"pair_{i+1}")
        os.makedirs(pair_dir, exist_ok=True)

        # ì´ë¯¸ì§€ ë³µì‚¬
        vertical_dst = os.path.join(pair_dir, "vertical.jpg")
        horizontal_dst = os.path.join(pair_dir, "horizontal.jpg")
        
        shutil.copy2(pair["vertical"], vertical_dst)
        shutil.copy2(pair["horizontal"], horizontal_dst)

        # ì ìˆ˜ ì •ë³´ ì €ì¥
        with open(os.path.join(pair_dir, "score.txt"), "w") as f:
            f.write(f"Similarity Score: {pair['score']:.4f}")

    print(f"ğŸ“ ë§¤ì¹­ëœ ì´ë¯¸ì§€ ìŒì´ `{movie_pairs_dir}`ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def process_movie_pair(movie_name, show_visualization=False, save_pairs=False):
    # 1. CLIP ëª¨ë¸ ë¡œë“œ
    model_name = "openai/clip-vit-base-patch32"
    model = CLIPModel.from_pretrained(model_name).to(DEVICE)
    processor = CLIPProcessor.from_pretrained(model_name, use_fast=True)

    # 2. ì´ë¯¸ì§€ íŒŒì¼ ë¡œë”© ë° ì„ë² ë”© ê³„ì‚°
    def encode_image(path):
        image = Image.open(path).convert("RGB")
        inputs = processor(images=image, return_tensors="pt").to(DEVICE)
        with torch.no_grad():
            feats = model.get_image_features(**inputs)
        return feats.cpu().numpy().squeeze()

    # ê°€ë¡œ/ì„¸ë¡œ ë¦¬ìŠ¤íŠ¸
    vertical_path = os.path.join(VERTICAL_DIR, movie_name)
    horizontal_path = os.path.join(HORIZONTAL_DIR, movie_name)
    
    if not os.path.exists(vertical_path) or not os.path.exists(horizontal_path):
        print(f"âš ï¸ Skipping {movie_name}: Missing vertical or horizontal directory")
        return
        
    vertical_files = sorted(os.listdir(vertical_path))
    horizontal_files = sorted(os.listdir(horizontal_path))

    if not vertical_files or not horizontal_files:
        print(f"âš ï¸ Skipping {movie_name}: No images found")
        return

    print(f"\nProcessing movie: {movie_name}")
    print(f"Vertical images: {len(vertical_files)}")
    print(f"Horizontal images: {len(horizontal_files)}")

    # ì„ë² ë”© ì‚¬ì „
    vert_embs = []
    for fn in tqdm(vertical_files, desc="Encoding vertical"):
        vert_embs.append(encode_image(os.path.join(vertical_path, fn)))
    horz_embs = []
    for fn in tqdm(horizontal_files, desc="Encoding horizontal"):
        horz_embs.append(encode_image(os.path.join(horizontal_path, fn)))

    V = np.stack(vert_embs)       # shape (N, 512)
    H = np.stack(horz_embs)       # shape (M, 512)

    # 3. ìœ ì‚¬ë„ í–‰ë ¬ (ì½”ì‚¬ì¸)
    V_norm = V / np.linalg.norm(V, axis=1, keepdims=True)
    H_norm = H / np.linalg.norm(H, axis=1, keepdims=True)
    sim_matrix = V_norm @ H_norm.T  # shape (N, M)

    # 4. Hungarian ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìµœì  1:1 ë§¤ì¹­
    row_ind, col_ind = linear_sum_assignment(-sim_matrix)

    pairs = []
    for v_idx, h_idx in zip(row_ind, col_ind):
        score = float(sim_matrix[v_idx, h_idx])
        if score >= 0.89:  # ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©
            pairs.append({
                "vertical": os.path.join(vertical_path, vertical_files[v_idx]),
                "horizontal": os.path.join(horizontal_path, horizontal_files[h_idx]),
                "score": score
            })

    # 5. ê²°ê³¼ ì €ì¥
    output_json = os.path.join(OUTPUT_DIR, f"{movie_name}.json")
    os.makedirs(os.path.dirname(output_json), exist_ok=True)
    with open(output_json, "w", encoding="utf-8") as f:
        json.dump(pairs, f, ensure_ascii=False, indent=2)

    print(f"âœ… {len(pairs)}ê°œ í˜ì–´ê°€ `{output_json}`ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # 6. ì‹œê°í™” (ì˜µì…˜)
    if show_visualization and pairs:
        print(f"ğŸ–¼ï¸ ì‹œê°í™” ê²°ê³¼ë¥¼ `{VISUALIZATION_DIR}/{movie_name}`ì— ì €ì¥í•©ë‹ˆë‹¤.")
        visualize_pairs(pairs, movie_name, show_visualization)

    # 7. ì´ë¯¸ì§€ ìŒ ë³µì‚¬ (ì˜µì…˜)
    if save_pairs and pairs:
        copy_paired_images(pairs, movie_name)

def main():
    parser = argparse.ArgumentParser(description='Process image pairs using CLIP model')
    parser.add_argument('--show', action='store_true', help='Show visualization results')
    parser.add_argument('--save', action='store_true', help='Save paired images in folders')
    args = parser.parse_args()

    # vertical ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ì˜í™” í´ë”ë¥¼ ìˆœíšŒ
    for movie_name in sorted(os.listdir(VERTICAL_DIR)):
        # pairs í´ë”ê°€ ìˆëŠ” ê²½ìš° ê±´ë„ˆëœ€
        if os.path.exists(os.path.join(OUTPUT_DIR, movie_name)):
            print(f"âš ï¸ Skipping {movie_name}: Already processed")
            continue
        process_movie_pair(movie_name, args.show, args.save)

if __name__ == "__main__":
    main()